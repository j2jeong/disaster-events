# crawler/merge_data.py

import json
import os

def merge_and_archive():
    """
    ì´ì „ì˜ 'events.json' ë°ì´í„°ë¥¼ 'past_events.json'ìœ¼ë¡œ ë³‘í•©í•˜ì—¬ ì•„ì¹´ì´ë¸Œí•©ë‹ˆë‹¤.
    - event_idë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.
    - ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.
    """
    repo_root = os.getenv('GITHUB_WORKSPACE', '.')
    past_events_path = os.path.join(repo_root, 'docs/data/past_events.json')
    current_events_path = os.path.join(repo_root, 'docs/data/events.json')

    print("ğŸ”„ ë°ì´í„° ì•„ì¹´ì´ë¸Œ ì‹œì‘...")

    # 1. ê³¼ê±° ë°ì´í„° ë¡œë“œ (íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘)
    try:
        with open(past_events_path, 'r', encoding='utf-8') as f:
            past_events = json.load(f)
        if not isinstance(past_events, list): past_events = []
        print(f"ğŸ—‚ï¸ '{past_events_path}'ì—ì„œ {len(past_events)}ê°œì˜ ê³¼ê±° ì´ë²¤íŠ¸ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except (FileNotFoundError, json.JSONDecodeError):
        past_events = []
        print(f"âš ï¸ '{past_events_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¹„ì–´ìˆì–´, ìƒˆ ì•„ì¹´ì´ë¸Œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")

    # 2. ì´ì „ ì‹¤í–‰ì—ì„œ ê°€ì ¸ì˜¨ 'ìµœì‹ ' ë°ì´í„° ë¡œë“œ
    try:
        with open(current_events_path, 'r', encoding='utf-8') as f:
            events_to_archive = json.load(f)
        if not isinstance(events_to_archive, list): events_to_archive = []
        print(f"ğŸ“‘ '{current_events_path}'ì—ì„œ {len(events_to_archive)}ê°œì˜ ì´ë²¤íŠ¸ë¥¼ ì•„ì¹´ì´ë¸Œ ëŒ€ìƒìœ¼ë¡œ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    except (FileNotFoundError, json.JSONDecodeError):
        events_to_archive = []
        print(f"â„¹ï¸ '{current_events_path}' íŒŒì¼ì´ ì—†ì–´ ì•„ì¹´ì´ë¸Œí•  ìƒˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if not events_to_archive:
        print("âœ… ì•„ì¹´ì´ë¸Œí•  ìƒˆ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # 3. event_idë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ì œê±° ë° ë³‘í•©
    # ì´ë ‡ê²Œ í•˜ë©´ ë™ì¼ IDì˜ ì´ë²¤íŠ¸ëŠ” ìµœì‹  ì •ë³´ë¡œ ë®ì–´ì¨ì§‘ë‹ˆë‹¤.
    events_map = {event['event_id']: event for event in past_events if event.get('event_id')}
    for event in events_to_archive:
        if event.get('event_id'):
            events_map[event['event_id']] = event
    
    merged_events = list(events_map.values())

    # 4. ë‚ ì§œ(event_date_utc) ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    merged_events.sort(key=lambda x: x.get('event_date_utc', ''), reverse=True)

    # 5. ê²°ê³¼ë¥¼ ë‹¤ì‹œ past_events.jsonì— ì €ì¥
    try:
        os.makedirs(os.path.dirname(past_events_path), exist_ok=True)
        with open(past_events_path, 'w', encoding='utf-8') as f:
            json.dump(merged_events, f, ensure_ascii=False, indent=2)
        print(f"âœ… ì„±ê³µ! ì´ {len(merged_events)}ê°œì˜ ì´ë²¤íŠ¸ê°€ '{past_events_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì•„ì¹´ì´ë¸Œ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit(1)

if __name__ == "__main__":
    merge_and_archive()